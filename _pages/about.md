---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---
<span style="font-size: 80%;">

I am a research scientist at Google DeepMind, Japan, working mainly on multimodal AI agents and alignment for diffusion models.
I received Ph.D. at The University of Tokyo, advised by [Yutaka Matsuo](http://ymatsuo.com/). I also received BEng and MEng at The University of Tokyo, advised by Yutaka Matsuo and closely collaborated with [Shixiang Shane Gu](https://sites.google.com/view/gugurus/home).
I was a Student Researcher at Google DeepMind, hosted by [Heiga Zen](https://scholar.google.com/citations?user=z3IRvDwAAAAJ) and [Izzeddin Gur](https://scholar.google.com/citations?user=qS_ugJAAAAAJ).


My recent research interest has focused on **AI agents** driven by multimodal LLMs for real-world applications (e.g., robotics, web navigation), **AI alignment** through deep reinforcement learning, and **mechanistic interpretablebility** of LLMs.


## Recent Preprints

1. Gouki Minegishi, <u>Hiroki Furuta</u>, Shohei Taniguchi, Yusuke Iwasawa, Yutaka Matsuo. <br>
**In-Context Meta Learning Induces Multi-Phase Circuit Emergence**  <br>
<span style="font-size: 70%;">_ICLR 2025 Workshop on Building Trust in Language Models and Applications [$^{*}$](https://building-trust-in-llms.github.io/iclr-workshop/)_.</span>  <br>
[[openreview](https://openreview.net/forum?id=LNMfzv8TNb)]

1. Lutfi Eren Erdogan, Nicholas Lee, Sehoon Kim, Suhong Moon, <u>Hiroki Furuta</u>, Gopala Anumanchipalli, Kurt Keutzer, Amir Gholami. <br>
**Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks** <br>
_arXiv preprint arXiv:2503.09572_, 2025. <br>
[[arxiv](https://arxiv.org/abs/2503.09572)]

1. Yuta Oshima, Masahiro Suzuki, Yutaka Matsuo, <u>Hiroki Furuta</u>. <br>
**Inference-Time Text-to-Video Alignment with Diffusion Latent Beam Search** <br>
_arXiv preprint arXiv:2501.19252_, 2025. <br>
[[arxiv](https://arxiv.org/abs/2501.19252)]

1. <u>Hiroki Furuta</u>, Heiga Zen, Dale Schuurmans, Aleksandra Faust, Yutaka Matsuo, Percy Liang, Sherry Yang. <br>
**Improving Dynamic Object Interactions in Text-to-Video Generation with AI Feedback** <br>
_arXiv preprint arXiv:2412.02617_, 2024. <br>
[[arxiv](https://arxiv.org/abs/2412.02617)] [[website](https://sites.google.com/view/aif-dynamic-t2v/)]


## Conference Publications

1. Gouki Minegishi, <u>Hiroki Furuta</u>, Yusuke Iwasawa, Yutaka Matsuo. <br>
**Rethinking Evaluation of Sparse Autoencoders through the Representation of Polysemous Words**  <br>
_International Conference on Learning Representations (ICLR 2025)_, 2025. <br>
[[arxiv](https://arxiv.org/abs/2501.06254)] [[code](https://github.com/gouki510/PS-Eval)]

1. <u>Hiroki Furuta</u>, Kuang-Huei Lee, Shixiang Shane Gu, Yutaka Matsuo, Aleksandra Faust, Heiga Zen, Izzeddin Gur. <br>
**Geometric-Averaged Preference Optimization for Soft Preference Labels**  <br>
_Neural Information Processing Systems (NeurIPS 2024)_. <br>
[[arxiv](https://arxiv.org/abs/2409.06691)]

1. Kuang-Huei Lee, Xinyun Chen, <u>Hiroki Furuta</u>, John Canny, Ian Fischer. <br>
**A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts**  <br>
_International Conference on Machine Learning (ICML 2024)_. <br>
[[arxiv](https://arxiv.org/abs/2402.09727)] [[website](https://read-agent.github.io/)]

1. Open X-Embodiment Collaboration, et al. (including <u>Hiroki Furuta</u>) <br>
**Open X-Embodiment: Robotic Learning Datasets and RT-X Models**  <br>
_IEEE International Conference on Robotics and Automation (ICRA 2024)_ (<span style="color: tomato; ">**Best Conference Paper Award**</span>). <br>
[[arxiv](https://arxiv.org/abs/2310.08864)] [[website](https://robotics-transformer-x.github.io/)]

1. Izzeddin Gur\*, <u>Hiroki Furuta</u>\*, Austin Huang, Mustafa Safdari, Yutaka Matsuo, Douglas Eck, Aleksandra Faust. (\*Equal Contribution)<br>
**A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis**  <br>
_International Conference on Learning Representations (ICLR 2024)_ (<span style="color: tomato; ">**Oral**</span>, 1.2% of 7262 submissions). <br>
[[arxiv](https://arxiv.org/abs/2307.12856)]

1. <u>Hiroki Furuta</u>, Kuang-Huei Lee, Ofir Nachum, Yutaka Matsuo, Aleksandra Faust, Shixiang Shane Gu, Izzeddin Gur. <br>
**Multimodal Web Navigation with Instruction-Finetuned Foundation Models**  <br>
_International Conference on Learning Representations (ICLR 2024)_. <br>
[[arxiv](https://arxiv.org/abs/2305.11854)] [[website](https://sites.google.com/view/mm-webnav/)]

1. <u>Hiroki Furuta</u>, Yusuke Iwasawa, Yutaka Matsuo, Shixiang Shane Gu. <br>
**A System for Morphology-Task Generalization via Unified Representation and Behavior Distillation** <br>
_International Conference on Learning Representations (ICLR 2023)_ (<span style="color: tomato; ">**Notable-top-25%**</span>, 8% of 4966 submissions). <br>
[[arxiv](https://arxiv.org/abs/2211.14296)] [[code](https://github.com/frt03/mxt_bench)] [[website](https://sites.google.com/view/control-graph)]

1. <u>Hiroki Furuta</u>, Yutaka Matsuo, Shixiang Shane Gu. <br>
**Generalized Decision Transformer for Offline Hindsight Information Matching**  <br>
_International Conference on Learning Representations (ICLR 2022)_ (<span style="color: tomato; ">**Spotlight**</span>, 5% of 3391 submissions). <br>
[[arxiv](https://arxiv.org/abs/2111.10364)] [[code](https://github.com/frt03/generalized_dt)] [[website](https://sites.google.com/view/generalizeddt)]

1. <u>Hiroki Furuta</u>, Tadashi Kozuno, Tatsuya Matsushima, Yutaka Matsuo, Shixiang Shane Gu. <br>
**Co-Adaptation of Algorithmic and Implementational Innovations in Inference-based Deep Reinforcement Learning**  <br>
_Neural Information Processing Systems (NeurIPS 2021)_. <br>
[[arxiv](https://arxiv.org/abs/2103.17258)] [[code](https://github.com/frt03/inference-based-rl)]

1. <u>Hiroki Furuta</u>, Tatsuya Matsushima, Tadashi Kozuno, Yutaka Matsuo, Sergey Levine, Ofir Nachum, Shixiang Shane Gu. <br>
**Policy Information Capacity: Information-Theoretic Measure for Task Complexity in Deep Reinforcement Learning**  <br>
_International Conference on Machine Learning (ICML 2021)_. <br>
[[arxiv](https://arxiv.org/abs/2103.12726)] [[code](https://github.com/frt03/pic)]

1. Tatsuya Matsushima\*, <u>Hiroki Furuta</u>\*, Yutaka Matsuo, Ofir Nachum, Shixiang Gu. (\*Equal Contribution)<br>
**Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization**  <br>
_International Conference on Learning Representations (ICLR 2021)_. <br>
[[openreview](https://openreview.net/forum?id=3hGNqpI4WS)] [[code](https://github.com/matsuolab/BREMEN)]


## Journal Publications

1. <u>Hiroki Furuta</u>, Yutaka Matsuo, Aleksandra Faust, Izzeddin Gur. <br>
**Exposing Limitations of Language Model Agents in Sequential-Task Compositions on the Web**  <br>
_Transactions on Machine Learning Research (TMLR)_, 2024. <br>
[[arxiv](https://arxiv.org/abs/2311.18751)] [[code](https://github.com/google-research/google-research/tree/master/compositional_rl/compwob)]

1. <u>Hiroki Furuta</u>, Gouki Minegishi, Yusuke Iwasawa, Yutaka Matsuo. <br>
**Towards Empirical Interpretation of Internal Circuits and Properties in Grokked Transformers on Modular Polynomials**  <br>
_Transactions on Machine Learning Research (TMLR)_, 2024. <br>
[[arxiv](https://arxiv.org/abs/2402.16726)] [[code](https://github.com/frt03/grok_mod_poly)]

1. So Kuroki, Tatsuya Matsushima, Junpei Arima, <u>Hiroki Furuta</u>, Yutaka Matsuo, Shixiang Shane Gu, Yujin Tang. <br>
**Collective Intelligence for 2D Push Manipulations With Mobile Robots** <br>
_IEEE Robotics and Automation Letters (RA-L)_, 2023. <br>
[[paper](https://ieeexplore.ieee.org/abstract/document/10080994)]


Please check [Publications](./publications.md) for further details.


## Talks

1. Hiroki Furuta. "Opportunities and Challenges of Language Model Agents in Web Automation". Berkeley Artificial Intelligence Research Lab, 2023.

1. Hiroki Furuta. "Co-Adaptation of Algorithmic and Implementational Innovations in Inference-based Deep Reinforcement Learning". NeurIPS Meetup Japan 2021 [$^{*}$](https://neuripsmeetup.jp/2021/), 2021.


## Academic Activitites

1. Reviewer for Neural Information Processing Systems (NeurIPS), 2021, 2022 <span style="font-size: 80%;">(**Top Reviewer**)</span>, 2023 <span style="font-size: 80%;">(**Top Reviewer**)</span>, 2024.

1. Reviewer for International Conference on Learning Representations (ICLR), 2022 <span style="font-size: 80%;">(**Highlighted Reviewer**)</span>, 2023, 2024, 2025.

1. Reviewer for International Conference on Machine Learning (ICML), 2021, 2022, 2023, 2024, 2025.

1. Reviewer for IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2025.

1. Reviewer for International Conference on Computer Vision (ICCV), 2025.

1. Reviewer for Association for Computational Linguistics (ACL) Rolling Review, 2025.

1. Reviewer for Transactions on Machine Learning Research (TMLR).

1. Reviewer for Advanced Robotics (AR).

1. Co-organizer for Ecological Theory of RL Workshop at NeurIPS [2021](https://sites.google.com/view/ecorl2021).

1. Program Committee for Foundation Models for Decision Making Workshop at NeurIPS [2022](https://sites.google.com/view/fmdm-neurips/), [2023](https://sites.google.com/view/fmdm-neurips23/).


## Honors & Awards

- Dean's Award (Ph.D.) <span style="font-size: 80%;">_(from Graduate School of Engineering, The University of Tokyo, 2025)_</span>
- Forbes JAPAN 30 UNDER 30 2023 <span style="font-size: 80%;">_(August, 2023)_</span>
- The Japan Society for the Promotion of Science Research Fellow (DC1) <span style="font-size: 80%;">_(April, 2022 - March, 2025)_</span>
- Dean's Award (Master) <span style="font-size: 80%;">_(from Graduate School of Engineering, The University of Tokyo, 2022)_</span>
- Toyota/Dwango Scholarship for Advanced Artificial Intelligence Researcher <span style="font-size: 80%;">_(April, 2021 - March, 2022)_</span>


## Education & Experience

- Research Scientist at Google DeepMind <span style="font-size: 80%;">_(2025 - Present)_</span>
- Ph.D. from The University of Tokyo <span style="font-size: 80%;">_(March, 2025)_</span>
- Student Researcher at Google DeepMind <span style="font-size: 80%;">_(May, 2023 - 2025)_</span>
- Student Researcher at Google Research, Brain Team <span style="font-size: 80%;">_(July, 2022 - May, 2023)_</span>
- MEng from The University of Tokyo <span style="font-size: 80%;">_(March, 2022)_</span>
- BEng from The University of Tokyo <span style="font-size: 80%;">_(March, 2020)_</span>
