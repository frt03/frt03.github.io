---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---


I am a master's student in Technology Management for Innovation at The University of Tokyo, working on Deep Reinforcement Learning. I am advised by [Yutaka Matsuo](http://ymatsuo.com/) and mentored by [Shixiang Shane Gu](https://sites.google.com/view/gugurus/home).

My research interest has focused on data-driven control towards real-world application, and the nature of environments in deep reinforcement learning.

# News
- 2021.05: Our paper: "Policy Information Capacity: Information-Theoretic Measure for Task Complexity in Deep Reinforcement Learning" has been accepted at ICML2021.

- 2021.04: Our paper: "Policy Information Capacity: Information-Theoretic Measure for Task Complexity in Deep Reinforcement Learning" has been accepted at [ICLR 2021 Workshop on Never-Ending RL](https://sites.google.com/view/neverendingrl) as Contributed Talk.

- 2021.01: Our paper: "Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization" has been accepted at ICLR2021.

# Pre-prints
1. <u>Hiroki Furuta</u>, Tadashi Kozuno, Tatsuya Matsushima, Yutaka Matsuo, Shixiang Shane Gu. <br>
**Co-Adaptation of Algorithmic and Implementational Innovations in Inference-based Deep Reinforcement Learning**  <br>
_arXiv preprint arXiv:2103.17258_, 2021. <br>
[[arxiv](https://arxiv.org/abs/2103.17258)] [[code](https://github.com/frt03/inference-based-rl)]

# Conference Publications
1. <u>Hiroki Furuta</u>, Tatsuya Matsushima, Tadashi Kozuno, Yutaka Matsuo, Sergey Levine, Ofir Nachum, Shixiang Shane Gu. <br>
**Policy Information Capacity: Information-Theoretic Measure for Task Complexity in Deep Reinforcement Learning**  <br>
_International Conference on Machine Learning (ICML2021)_. <br>
[[arxiv](https://arxiv.org/abs/2103.12726)] [[code](https://github.com/frt03/pic)]

2. Tatsuya Matsushima\*, <u>Hiroki Furuta</u>\*, Yutaka Matsuo, Ofir Nachum, Shixiang Gu. (\*Equal Contribution)<br>
**Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization**  <br>
_International Conference on Learning Representations (ICLR2021)_. <br>
[[openreview](https://openreview.net/forum?id=3hGNqpI4WS)] [[code](https://github.com/matsuolab/BREMEN)]

# Workshop Papers
1. <u>Hiroki Furuta</u>, Tatsuya Matsushima, Tadashi Kozuno, Yutaka Matsuo, Sergey Levine, Ofir Nachum, Shixiang Shane Gu. <br>
**Policy Information Capacity: Information-Theoretic Measure for Task Complexity in Deep Reinforcement Learning**  <br>
_[ICLR 2021 Workshop on Never-Ending RL](https://sites.google.com/view/neverendingrl)_. (Contributed Talk)

2. <u>Hiroki Furuta</u>, Tadashi Kozuno, Tatsuya Matsushima, Yutaka Matsuo, Shixiang Shane Gu. <br>
**A Unified View of Inference-based Off-Policy RL: Decoupling Algorithmic and Implementational Sources of Performance Differences**  <br>
_[NeurIPS 2020 Deep Reinforcement Learning Workshop](https://sites.google.com/view/deep-rl-workshop-neurips2020/home)_

3. Tatsuya Matsushima\*, <u>Hiroki Furuta</u>\*, Yutaka Matsuo, Ofir Nachum, Shixiang Gu. (\*Equal Contribution)<br>
**Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization**  <br>
_[NeurIPS 2020 Offline Reinforcement Learning Workshop](https://offline-rl-neurips.github.io/)_

4. Tatsuya Matsushima\*, <u>Hiroki Furuta</u>\*, Yutaka Matsuo, Ofir Nachum, Shixiang Gu. (\*Equal Contribution)<br>
**Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization**  <br>
_[Bay Area Machine Learning Symposium 2020](https://baylearn2020.splashthat.com/)_


# Academic Activitites
1. Reviewer for Neural Information Processing Systems (NeurIPS), 2021.

2. Reviewer for International Conference on Machine Learning (ICML), 2021.
