---
layout: archive
title: ""
permalink: /publications/
author_profile: true
---
<span style="font-size: 80%;">

## Conference Publications

1. Gouki Minegishi, <u>Hiroki Furuta</u>, Shohei Taniguchi, Yusuke Iwasawa, Yutaka Matsuo. <br>
**In-Context Meta Learning Induces Multi-Phase Circuit Emergence**  <br>
_International Conference on Machine Learning (ICML 2025)_. <br>
[[openreview](https://openreview.net/forum?id=LNMfzv8TNb)]

1. Lutfi Eren Erdogan, Nicholas Lee, Sehoon Kim, Suhong Moon, <u>Hiroki Furuta</u>, Gopala Anumanchipalli, Kurt Keutzer, Amir Gholami. <br>
**Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks** <br>
_International Conference on Machine Learning (ICML 2025)_. <br>
[[arxiv](https://arxiv.org/abs/2503.09572)]

1. Gouki Minegishi, <u>Hiroki Furuta</u>, Yusuke Iwasawa, Yutaka Matsuo. <br>
**Rethinking Evaluation of Sparse Autoencoders through the Representation of Polysemous Words**  <br>
_International Conference on Learning Representations (ICLR 2025)_. <br>
[[arxiv](https://arxiv.org/abs/2501.06254)] [[code](https://github.com/gouki510/PS-Eval)]

1. <u>Hiroki Furuta</u>, Kuang-Huei Lee, Shixiang Shane Gu, Yutaka Matsuo, Aleksandra Faust, Heiga Zen, Izzeddin Gur. <br>
**Geometric-Averaged Preference Optimization for Soft Preference Labels**  <br>
_Neural Information Processing Systems (NeurIPS 2024)_. <br>
[[arxiv](https://arxiv.org/abs/2409.06691)]

1. Kuang-Huei Lee, Xinyun Chen, <u>Hiroki Furuta</u>, John Canny, Ian Fischer. <br>
**A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts**  <br>
_International Conference on Machine Learning (ICML 2024)_. <br>
[[arxiv](https://arxiv.org/abs/2402.09727)] [[website](https://read-agent.github.io/)]

1. Open X-Embodiment Collaboration, et al. (including <u>Hiroki Furuta</u>) <br>
**Open X-Embodiment: Robotic Learning Datasets and RT-X Models**  <br>
_IEEE International Conference on Robotics and Automation (ICRA 2024)_ (<span style="color: tomato; ">**Best Conference Paper Award**</span>). <br>
[[arxiv](https://arxiv.org/abs/2310.08864)] [[website](https://robotics-transformer-x.github.io/)]

1. Izzeddin Gur\*, <u>Hiroki Furuta</u>\*, Austin Huang, Mustafa Safdari, Yutaka Matsuo, Douglas Eck, Aleksandra Faust. (\*Equal Contribution)<br>
**A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis**  <br>
_International Conference on Learning Representations (ICLR 2024)_ (<span style="color: tomato; ">**Oral**</span>, 1.2% of 7262 submissions). <br>
[[arxiv](https://arxiv.org/abs/2307.12856)]

1. <u>Hiroki Furuta</u>, Kuang-Huei Lee, Ofir Nachum, Yutaka Matsuo, Aleksandra Faust, Shixiang Shane Gu, Izzeddin Gur. <br>
**Multimodal Web Navigation with Instruction-Finetuned Foundation Models**  <br>
_International Conference on Learning Representations (ICLR 2024)_. <br>
[[arxiv](https://arxiv.org/abs/2305.11854)] [[website](https://sites.google.com/view/mm-webnav/)]

1. <u>Hiroki Furuta</u>, Yusuke Iwasawa, Yutaka Matsuo, Shixiang Shane Gu. <br>
**A System for Morphology-Task Generalization via Unified Representation and Behavior Distillation** <br>
_International Conference on Learning Representations (ICLR 2023)_ (<span style="color: tomato; ">**Notable-top-25%**</span>, 8.0% of 4966 submissions). <br>
[[arxiv](https://arxiv.org/abs/2211.14296)] [[code](https://github.com/frt03/mxt_bench)] [[website](https://sites.google.com/view/control-graph)]

1. <u>Hiroki Furuta</u>, Yutaka Matsuo, Shixiang Shane Gu. <br>
**Generalized Decision Transformer for Offline Hindsight Information Matching**  <br>
_International Conference on Learning Representations (ICLR 2022)_ (<span style="color: tomato; ">**Spotlight**</span>, 6.8% of 3391 submissions). <br>
[[arxiv](https://arxiv.org/abs/2111.10364)] [[code](https://github.com/frt03/generalized_dt)] [[website](https://sites.google.com/view/generalizeddt)]

1. <u>Hiroki Furuta</u>, Tadashi Kozuno, Tatsuya Matsushima, Yutaka Matsuo, Shixiang Shane Gu. <br>
**Co-Adaptation of Algorithmic and Implementational Innovations in Inference-based Deep Reinforcement Learning**  <br>
_Neural Information Processing Systems (NeurIPS 2021)_. <br>
[[arxiv](https://arxiv.org/abs/2103.17258)] [[code](https://github.com/frt03/inference-based-rl)]

1. <u>Hiroki Furuta</u>, Tatsuya Matsushima, Tadashi Kozuno, Yutaka Matsuo, Sergey Levine, Ofir Nachum, Shixiang Shane Gu. <br>
**Policy Information Capacity: Information-Theoretic Measure for Task Complexity in Deep Reinforcement Learning**  <br>
_International Conference on Machine Learning (ICML 2021)_. <br>
[[arxiv](https://arxiv.org/abs/2103.12726)] [[code](https://github.com/frt03/pic)]

1. Tatsuya Matsushima\*, <u>Hiroki Furuta</u>\*, Yutaka Matsuo, Ofir Nachum, Shixiang Gu. (\*Equal Contribution)<br>
**Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization**  <br>
_International Conference on Learning Representations (ICLR 2021)_. <br>
[[openreview](https://openreview.net/forum?id=3hGNqpI4WS)] [[code](https://github.com/matsuolab/BREMEN)]


## Journal Publications
1. <u>Hiroki Furuta</u>, Yutaka Matsuo, Aleksandra Faust, Izzeddin Gur. <br>
**Exposing Limitations of Language Model Agents in Sequential-Task Compositions on the Web**  <br>
_Transactions on Machine Learning Research (TMLR)_, 2024. <br>
[[arxiv](https://arxiv.org/abs/2311.18751)] [[code](https://github.com/google-research/google-research/tree/master/compositional_rl/compwob)]

1. <u>Hiroki Furuta</u>, Gouki Minegishi, Yusuke Iwasawa, Yutaka Matsuo. <br>
**Towards Empirical Interpretation of Internal Circuits and Properties in Grokked Transformers on Modular Polynomials**  <br>
_Transactions on Machine Learning Research (TMLR)_, 2024. <br>
[[arxiv](https://arxiv.org/abs/2402.16726)] [[code](https://github.com/frt03/grok_mod_poly)]

1. So Kuroki, Tatsuya Matsushima, Junpei Arima, <u>Hiroki Furuta</u>, Yutaka Matsuo, Shixiang Shane Gu, Yujin Tang. <br>
**Collective Intelligence for 2D Push Manipulations With Mobile Robots** <br>
_IEEE Robotics and Automation Letters (RA-L)_, 2023. <br>
[[paper](https://ieeexplore.ieee.org/abstract/document/10080994)]


## Preprints

1. Yuta Oshima, Masahiro Suzuki, Yutaka Matsuo, <u>Hiroki Furuta</u>. <br>
**Inference-Time Text-to-Video Alignment with Diffusion Latent Beam Search** <br>
_arXiv preprint arXiv:2501.19252_, 2025. <br>
[[arxiv](https://arxiv.org/abs/2501.19252)]

1. <u>Hiroki Furuta</u>, Heiga Zen, Dale Schuurmans, Aleksandra Faust, Yutaka Matsuo, Percy Liang, Sherry Yang. <br>
**Improving Dynamic Object Interactions in Text-to-Video Generation with AI Feedback** <br>
_arXiv preprint arXiv:2412.02617_, 2024. <br>
[[arxiv](https://arxiv.org/abs/2412.02617)] [[website](https://sites.google.com/view/aif-dynamic-t2v/)]

1. Shixiang Shane Gu, Manfred Diaz, C. Daniel Freeman, <u>Hiroki Furuta</u>, Seyed Kamyar Seyed Ghasemipour, Anton Raichuk, Byron David, Erik Frey, Erwin Coumans, Olivier Bachem. <br>
**Braxlines: Fast and Interactive Toolkit for RL-driven Behavior Generation Beyond Reward Maximization**  <br>
_arXiv preprint arXiv:2110.04686_, 2021. <br>
[[arxiv](https://arxiv.org/abs/2110.04686)] [[code](https://github.com/google/brax/tree/main/brax/experimental/braxlines/)]


## Workshop Presentations
1. Gouki Minegishi, <u>Hiroki Furuta</u>, Shohei Taniguchi, Yusuke Iwasawa, Yutaka Matsuo. <br>
**In-Context Meta Learning Induces Multi-Phase Circuit Emergence**  <br>
<span style="font-size: 70%;">_ICLR 2025 Workshop on Building Trust in Language Models and Applications [$^{*}$](https://building-trust-in-llms.github.io/iclr-workshop/)_ (<span style="color: tomato; ">**Oral**</span>). </span>

1. Kuang-Huei Lee, Xinyun Chen, <u>Hiroki Furuta</u>, John Canny, Ian Fischer. <br>
**A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts**  <br>
<span style="font-size: 70%;">
_ICLR 2024 Workshop on Large Language Model (LLM) Agents [$^{*}$](https://llmagents.github.io/)_.
</span>

1. <u>Hiroki Furuta</u>, Gouki Minegishi, Yusuke Iwasawa, Yutaka Matsuo. <br>
**Interpreting Grokked Transformers in Complex Modular Arithmetic**  <br>
<span style="font-size: 70%;">_ICLR 2024 Workshop Bridging the Gap Between Practice and Theory in Deep Learning [$^{*}$](https://sites.google.com/view/bgpt-iclr24)_ (<span style="color: tomato; ">**Oral**</span>). </span> 


1. <u>Hiroki Furuta</u>, Yutaka Matsuo, Aleksandra Faust, Izzeddin Gur. <br>
**Exposing Limitations of Language Model Agents in Sequential-Task Compositions on the Web**  <br>
<span style="font-size: 70%;">
_NeurIPS 2023 Foundation Models for Decision Making Workshop [$^{*}$](https://sites.google.com/view/fmdm-neurips23/)_  <br>
_ICLR 2024 Workshop on Large Language Model (LLM) Agents [$^{*}$](https://llmagents.github.io/)_.
</span>

1. Open X-Embodiment Collaboration, et al. <br>
**Open X-Embodiment: Robotic Learning Datasets and RT-X Models** <br>
<span style="font-size: 70%;">
_CoRL 2023 2nd Workshop on Language and Robot Learning (LangRob): Language as Grounding 
 [$^{*}$](https://sites.google.com/view/langrob-corl23/home/)_ <br>
_CoRL 2023 Towards Generalist Robots:
Learning Paradigms for Scalable Skill Acquisition [$^{*}$](https://generalist-robots.github.io/)_ (<span style="color: tomato; ">**Oral**</span>) <br>
_NeurIPS 2023 6th Robot Learning Workshop: Pretraining, Fine-Tuning, and Generalization with Large Scale Models [$^{*}$](https://www.robot-learning.ml/2023/)_.
</span>

1. <u>Hiroki Furuta</u>, Ofir Nachum, Kuang-Huei Lee, Yutaka Matsuo, Shixiang Shane Gu, Izzeddin Gur. <br>
**Instruction-Finetuned Foundation Models for Multimodal Web Navigation** <br>
<span style="font-size: 70%;">
_ICLR 2023 Workshop on Multimodal Representation Learning [$^{*}$](https://mrl-workshop.github.io/iclr-2023/)_ (<span style="color: tomato; ">**Spotlight**</span>) <br>
_ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models [$^{*}$](https://sites.google.com/view/me-fomo2023)_ <br>
_ICLR 2023 Workshop on Reincarnating Reinforcement Learning [$^{*}$](https://reincarnating-rl.github.io/)_.
</span>

1. <u>Hiroki Furuta</u>, Yusuke Iwasawa, Yutaka Matsuo, Shixiang Shane Gu. <br>
**Control Graph as Unified IO for Morphology-Task Generalization** <br>
<span style="font-size: 70%;">
_NeurIPS 2022 3rd Offline Reinforcement Learning Workshop: Offline RL as a "Launchpad" [$^{*}$](https://offline-rl-neurips.github.io/2022/)_ (<span style="color: tomato; ">**Contributed Talk**</span>) <br>
_NeurIPS 2022 Foundation Models for Decision Making Workshop [$^{*}$](https://sites.google.com/view/fmdm-neurips/)_.
</span>

1. <u>Hiroki Furuta</u>, Yutaka Matsuo, Shixiang Shane Gu. <br>
**Generalized Decision Transformer for Offline Hindsight Information Matching**  <br>
<span style="font-size: 70%;">_NeurIPS 2021 Deep Reinforcement Learning Workshop [$^{*}$](https://sites.google.com/view/deep-rl-workshop-neurips2021/)_.</span>

1. <u>Hiroki Furuta</u>, Tatsuya Matsushima, Tadashi Kozuno, Yutaka Matsuo, Sergey Levine, Ofir Nachum, Shixiang Shane Gu. <br>
**Policy Information Capacity: Information-Theoretic Measure for Task Complexity in Deep Reinforcement Learning**  <br>
<span style="font-size: 70%;">_ICLR 2021 Workshop on Never-Ending RL [$^{*}$](https://sites.google.com/view/neverendingrl/)_ (<span style="color: tomato; ">**Contributed Talk**</span>).</span>

1. <u>Hiroki Furuta</u>, Tadashi Kozuno, Tatsuya Matsushima, Yutaka Matsuo, Shixiang Shane Gu. <br>
**A Unified View of Inference-based Off-Policy RL: Decoupling Algorithmic and Implementational Sources of Performance Differences**  <br>
<span style="font-size: 70%;">_NeurIPS 2020 Deep Reinforcement Learning Workshop [$^{*}$](https://sites.google.com/view/deep-rl-workshop-neurips2020/)_.</span>

1. Tatsuya Matsushima\*, <u>Hiroki Furuta</u>\*, Yutaka Matsuo, Ofir Nachum, Shixiang Gu. (\*Equal Contribution)<br>
**Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization**  <br>
<span style="font-size: 70%;">
_NeurIPS 2020 Offline Reinforcement Learning Workshop [$^{*}$](https://offline-rl-neurips.github.io/)_, <br>
_Bay Area Machine Learning Symposium 2020 [$^{*}$](https://baylearn2020.splashthat.com/)_.
</span>
